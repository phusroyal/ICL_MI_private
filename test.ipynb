{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phu.hoang/.conda/envs/icl_mi/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2-xl')\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2-xl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoded_ids_align(inputs, decoded, outputs):\n",
    "    inputs_ids = inputs['input_ids'].squeeze()\n",
    "    # make outputs as keys of tok_ids\n",
    "    tok_ids = {}\n",
    "\n",
    "    for tok, ids in zip(decoded, inputs_ids):\n",
    "        if any(f in tok for f in outputs):\n",
    "            tok_ids[tok] = ids\n",
    "\n",
    "    return tok_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['b', 'd', 'c', 'a', 'e'], ['b', 'e', 'a', 'd', 'c'], ['e', 'b', 'd', 'a', 'c'], ['c', 'a', 'b', 'e', 'd'], ['b', 'a', 'd', 'e', 'c']]\n"
     ]
    }
   ],
   "source": [
    "# shuffle a list n times\n",
    "def list_shuffle(lst, n):\n",
    "    import random\n",
    "    new_lsts = []\n",
    "    for _ in range(n):\n",
    "        lst_cp = lst.copy()\n",
    "        random.shuffle(lst_cp)\n",
    "        new_lsts.append(lst_cp)\n",
    "    return new_lsts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_data_json(file):\n",
    "    \"\"\"Load data from json file\"\"\"\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        prompt_data = data[\"prompts_list\"]\n",
    "    \n",
    "    prompt_ult = []\n",
    "    preds_ult = []\n",
    "    outputs_ult = []\n",
    "\n",
    "    for prompts in prompt_data:\n",
    "        prompt_shuffled = list_shuffle(prompts, 50)\n",
    "        prompt_list = []\n",
    "        preds = []\n",
    "        outputs = []\n",
    "        for prompt in prompt_shuffled:\n",
    "            outputs.append(set([de.split()[-1] for de in prompt]))\n",
    "            p = \" \".join(prompt[:-1])\n",
    "            last_prompt = prompt[-1].split()\n",
    "            for i in range(0, len(last_prompt)-1):\n",
    "                p += \" \" + last_prompt[i]\n",
    "            prompt_list.append(p)\n",
    "            preds.append(last_prompt[-1])\n",
    "        prompt_ult.append(prompt_list)\n",
    "        preds_ult.append(preds)\n",
    "        outputs_ult.append(outputs)\n",
    "    return prompt_ult, preds_ult, outputs_ult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/info_17/selection_17.json'\n",
    "\n",
    "prompt_list, labels_list, outputs_list = load_data_json(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [01:15,  1.50s/it]\n",
      "50it [01:15,  1.51s/it]\n",
      "50it [01:13,  1.47s/it]\n",
      "50it [01:16,  1.53s/it]\n",
      "50it [01:15,  1.51s/it]\n",
      "50it [01:13,  1.47s/it]\n",
      "50it [01:16,  1.52s/it]\n",
      "50it [01:14,  1.49s/it]\n",
      "50it [01:13,  1.48s/it]\n",
      "50it [01:14,  1.49s/it]\n",
      "50it [01:13,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8418181818181819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "preds = []\n",
    "for prompts, labels, outputs in zip(prompt_list, labels_list, outputs_list):\n",
    "    pred = []\n",
    "    for prompt, label, output in tqdm(zip(prompts, labels, outputs)):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        decoded_tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        tok_ids_dict = decoded_ids_align(inputs, decoded_tokens, output)\n",
    "        logits = model(**inputs).logits\n",
    "        scores = [logits[0][-1][list(tok_ids_dict.values())[i]] for i in range(0, len(tok_ids_dict))]\n",
    "        # get the index of the max score\n",
    "        max_score_index = scores.index(max(scores))\n",
    "        # get the token of the max score\n",
    "        max_score_token = list(tok_ids_dict.keys())[max_score_index]\n",
    "        # get the predicted token\n",
    "        max_score_token = next((o for o in output if o in max_score_token), max_score_token)\n",
    "        pred.append(max_score_token)\n",
    "    preds.append(pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = []\n",
    "for labels, pred in zip(labels_list, preds):\n",
    "    acc.append(accuracy_score(labels, pred))\n",
    "print(sum(acc)/len(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/info_15/selection_15.json'\n",
    "\n",
    "prompt_list, labels_list, outputs_list = load_data_json(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [01:33,  1.88s/it]\n",
      "50it [01:39,  2.00s/it]\n",
      "50it [01:39,  1.99s/it]\n",
      "50it [01:35,  1.92s/it]\n",
      "50it [01:39,  1.99s/it]\n",
      "50it [01:35,  1.91s/it]\n",
      "50it [01:34,  1.89s/it]\n",
      "50it [01:34,  1.89s/it]\n",
      "50it [01:35,  1.91s/it]\n",
      "50it [01:40,  2.01s/it]\n",
      "50it [01:35,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41818181818181815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "preds = []\n",
    "for prompts, labels, outputs in zip(prompt_list, labels_list, outputs_list):\n",
    "    pred = []\n",
    "    for prompt, label, output in tqdm(zip(prompts, labels, outputs)):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        decoded_tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        tok_ids_dict = decoded_ids_align(inputs, decoded_tokens, output)\n",
    "        logits = model(**inputs).logits\n",
    "        scores = [logits[0][-1][list(tok_ids_dict.values())[i]] for i in range(0, len(tok_ids_dict))]\n",
    "        # get the index of the max score\n",
    "        max_score_index = scores.index(max(scores))\n",
    "        # get the token of the max score\n",
    "        max_score_token = list(tok_ids_dict.keys())[max_score_index]\n",
    "        # get the predicted token\n",
    "        max_score_token = next((o for o in output if o in max_score_token), max_score_token)\n",
    "        pred.append(max_score_token)\n",
    "    preds.append(pred)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = []\n",
    "for labels, pred in zip(labels_list, preds):\n",
    "    acc.append(accuracy_score(labels, pred))\n",
    "print(sum(acc)/len(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icl_mi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
